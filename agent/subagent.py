# subagents.py

from agents import Agent, Runner, ModelSettings
from agents.tool import function_tool
from typing import Dict, Any
import os
import pickle
import asyncio

''' Subagents for various tasks related to code modification and verification. '''



# ------------------ 1. Verifier ------------------
@function_tool
async def verify_path(path: str) -> Dict[str, Any]:
    """
    Generic checker: verify a single filesystem path exists.
    """
    if not os.path.exists(path):
        return {"ok": False, "missing": path}
    return {"ok": True}
@function_tool
async def ask_human(prompt: str) -> Dict[str, str]:
    """Display *prompt* in the console and return the userâ€™s reply."""
    return {"human_input": await asyncio.to_thread(input, f"\nðŸ‘¤ {prompt}\n> ")}

# ask_human = function_tool(
#     func=_ask_human_impl,
#     tool_name="ask_human",
#     tool_description="Prompt the user with a question and return their response"
# )

PathVerifier = Agent(
    name="PathVerifier",
    instructions="""
You are a helper that ensures the user supplies a valid filesystem path.

1. You will be called with a single argument: {"purpose": "<forward|inverse>"}.
2. If purpose is "forward", your target file is "desp_flex.txt".
   If purpose is "inverse", your target files are:
     - "model_final.pth"
     - "x_scaler.save"
     - "y_scaler.save"
3. For each target file:
   a) Call verify_path(path).  
      - If it returns ok=True, move on.  
      - If it returns ok=False, use ask_human(...) to prompt:
        "The file '<missing>' is missing. Please upload the file for <purpose>."
      - Take the user's reply as the new path and repeat step 3a for that file.
4. After all target files exist, return {"status":"ok"}.
""",
    tools=[verify_path,ask_human],
    model="o4-mini",
    model_settings=   ModelSettings(
    )
)
# ------------------ 2. Forward Trainer Subagent ------------------

# @function_tool
# async def forward_train(dataset_size: int) -> dict:
#     """
#     Spins up an AIDE experiment at `dataset_size`, runs it,
#     and parses out the Validation MSE and generated code.
#     Returns {'mse': float, 'code': str}.
#     """
#     from forward_loop import code_data_loop, generate_dataset
#     generate_dataset(dataset_size)  
#     res = code_data_loop(dataset_size)  
#     #save the code
#     with open("code_aideml.py", "w", encoding="utf-8") as f:
#         f.write( res["code"])                            
#     return res
@function_tool
async def generate_datasets(dataset_size: int) -> None:
    from forward_loop import generate_dataset
    generate_dataset(dataset_size)
    return {"status": f"datasets {dataset_size} generated"}

@function_tool
async def code_data_loops(dataset_size: int) -> dict:
    from forward_loop import code_data_loop, generate_dataset
    # generate_dataset(dataset_size)
    # was: res = code_data_loop(dataset_size)  # sync + missing maxsize arg
    code, final_size = await code_data_loop(dataset_size, maxsize=41000)
    # save the code
    with open("best_solution.py", "w", encoding="utf-8") as f:
        f.write(code)
    return {
        "code": code,
        "final_size": final_size,
        "conlusion": f"Completed loop at size={final_size}"
    }

ForwardTrainer = Agent(
    name="ForwardTrainer",
    instructions="""
You are the Forward Trainer agent. You will be given a single integer argument: `dataset_size`.
1. Call `generate_datasets(dataset_size)` to write out the training/validation/test CSV files with inital dataset size.
2. Invoke `code_data_loops(dataset_size)` to run the AIDE and dataset size optimize loop; it returns `(code, final_size)`.
3. Capture those two values:
   - `code`: the final Python source generated by AIDE.
   - `final_size`: the dataset size actually used in the last step.
4. Return exactly the dict:
   {
     "code": <the final code string>,
     "final_size": <the final dataset size integer>,
     "conlusion": <the summary of the process>,
   }
    """,
    tools=[code_data_loops, generate_datasets],
    model="o4-mini",
    model_settings=   ModelSettings(
    )
)

# ------------------ 3. Inverse Designer Subagent ------------------

@function_tool
async def code_verify() -> str:
    max_rounds = 4
    from modifier import _run_code, _make_agent
    agent = _make_agent()
    with open("best_solution.py", "r", encoding="utf-8") as f:
        raw_code = f.read()
    user_input = raw_code
    patched = None

    for round_idx in range(1, max_rounds + 1):
        # was: resp = Runner.run_sync(agent, user_input)
        resp = await Runner.run(agent, user_input)
        patched = resp.final_output
        result = _run_code(patched)
        if result["ok"]:
            print(f"âœ… Round {round_idx}: script ran successfully.")
            break
        traceback = result["stderr"] or "(no stderr)"
        print(f"âš ï¸  Round {round_idx} failed â€“ feeding traceback back to agent.\n{traceback}\n")
        user_input = (
            "The previous patch still fails. Here is the code followed by the full traceback. "
            "Please fix all errors and return an updated runnable script.\n\n"
            "```python\n" + patched + "\n```\n\n"
            "Traceback:\n```\n" + traceback + "\n```"
        )
        agent = _make_agent()

    with open("modified.py", "w") as f:
        f.write(patched)

    return f"fixed, Final file written to  modified.py"

@function_tool
async def inverse_design(
    test_data_path: str,
) -> dict:
    """
    Calls your Neural Adjoint inverse design pipeline and returns
    {"inverse_performance_mse": float}.
    """
    from inverse_NA import inverse_one
    return inverse_one(
        test_data_path
    )                                                      
InverseDesigner = Agent(
    name="InverseDesigner",
    instructions="""
You are the Inverse Designer agent. You will be given one argument:
- `test_data_path`: the path to the target spectrum file (CSV).

Your steps:
1. Call `code_verify()` to patch and verify the Python source.
2. After verifying, call `inverse_design(test_data_path)` which runs the Neural Adjoint pipeline.
3. `inverse_design` returns a dict with key `"inverse_performance_mse"`.
4. Return exactly the dict:
   {
     "Surrogate MSE": mse , "Real MSE": mse_real
   }
""",
    tools=[code_verify, inverse_design],
    model="o4-mini",
    model_settings=   ModelSettings(
    )
)
# ------------------ 4. test ------------------
if __name__ == "__main__":
    code_verify()